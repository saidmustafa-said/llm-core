this 2 files send api request to the llama api and get a response. they are similar so i want to build a interface and then inside the interface we can write the common functions that will be used in both files. In testing it is kinda expensive to always send a new request to the api. So we can cache the response and use it again. cache it into a file.json or what other pyc or something so when the input is the same we can just read the file and return from there. do you have a better idea? and then in prod we can easily turn off the caching system or even upgrade the caching system to a more better one so we can even build a class for that. give me your thoughts make it's caching system interface too so it is easily replaceable later to another technology such as redis or something. but for now lets use joblib


# src/llamarequest.py
import os
import pandas as pd
from src.utils import timing_decorator
from src.data_types import LLMResponse
from typing import List, Optional
from src.function_api_builder import create_classification_request
from src.core.logger_setup import get_logger
import json

from src.config.config import ConfigManager


def extract_content(response):
    """Extracts the JSON content from the response's 'content' field."""
    try:
        # Navigate to the content field
        content_str = response.get("choices", [{}])[0].get(
            "message", {}).get("content", "")

        # Parse the JSON
        extracted_json = json.loads(content_str)

        return extracted_json
    except (json.JSONDecodeError, IndexError, KeyError) as e:
        print(f"Error extracting content: {e}")
        return None


@timing_decorator
def llm_api(prompt: str, subcategories) -> LLMResponse:
    config = ConfigManager()
    LLAMA_API = config.get_llama_api()

    logger = get_logger()
    logger.info("Calling LLM API with the provided prompt.")

    # user_history = history if history else "No previous conversation"
    existing_subcategories_str = subcategories
    print(existing_subcategories_str)

    logger.debug(f"Existing subcategories: {existing_subcategories_str}")
    # logger.debug("User history: %s", user_history.replace('\n', ' || '))

    # Prepare the API request
    api_request_json = create_classification_request(
        prompt, existing_subcategories_str, )
    logger.debug(
        f"API request JSON from create_classification_request: {api_request_json}")

    # Call the LLAMA API
    try:
        response = LLAMA_API.run(api_request_json)
        print("Response from LLAMA API:", response.json())
        logger.info("Received response from LLAMA API.")
        logger.debug(f"Response: {response.json()}")
    except Exception as e:
        logger.error(f"Error calling LLAMA API: {e}")
        return LLMResponse({"error": "Failed to call LLAMA API"})

    # Extract and parse JSON from the response
    extracted_json = extract_content(response.json())

    return extracted_json


# src/get_location_advice.py

from typing import List, Optional, Dict
import re
import json
import numpy as np
import uuid
# from config import LLAMA_API
from src.utils import timing_decorator

from src.data_types import TopCandidates, LocationAdviceResponse
from src.function_api_builder import build_location_request, build_location_request_search
from src.core.logger_setup import get_logger
from src.config.config import ConfigManager


def format_top_candidates(top_candidates: TopCandidates) -> str:
    """
    Format top candidate points of interest into a readable string.
    Handles numpy types and None values properly.
    """
    logger = get_logger()
    lines = []

    for mode, candidates in top_candidates.items():
        lines.append(f"{mode.capitalize()} Mode:")

        if candidates and len(candidates) > 0:
            for poi in candidates:
                details = [f"Mode: {mode.capitalize()}"]

                for key, value in poi.items():
                    # Convert numpy types to Python native types
                    if isinstance(value, np.generic):
                        value = value.item()  # Replaced np.asscalar with .item()

                    if value is None or (isinstance(value, float) and np.isnan(value)):
                        continue

                    if isinstance(value, dict):
                        for sub_key, sub_value in value.items():
                            if isinstance(sub_value, np.generic):
                                sub_value = sub_value.item()  # Replaced np.asscalar with .item()
                            if sub_value is None or (isinstance(sub_value, float) and np.isnan(sub_value)):
                                continue
                            details.append(
                                f"{sub_key.capitalize()}: {sub_value}")
                    else:
                        details.append(f"{key.capitalize()}: {value}")

                lines.append("\n".join(details))
        else:
            lines.append(
                f"No locations found within the specified route distance for {mode} mode.")

    logger.debug("Formatted top candidates: %s", "\n\n".join(lines))
    return "\n\n".join(lines) if lines else "No location data available."


def extract_content(response):
    """Extracts the JSON content from the response's 'content' field."""
    try:
        # Navigate to the content field
        content_str = response.get("choices", [{}])[0].get(
            "message", {}).get("content", "")

        # Parse the JSON
        extracted_json = json.loads(content_str)

        return extracted_json
    except (json.JSONDecodeError, IndexError, KeyError) as e:
        print(f"Error extracting content: {e}")
        return None


@timing_decorator
def get_location_advice(prompt, history, top_candidates: TopCandidates,
                        latitude, longitude, search_radius, flag=False) -> LocationAdviceResponse:
    """Main function to get location advice with structured response handling

    Returns:
        Dict containing:
        - response: str - The text response to the user
        - continuation: bool - Whether the conversation should continue
        - recommendations: List[Dict[str, str]] - List of recommended locations with details
        - error: Optional[str] - Error message if any
        - token_counts: Dict[str, int] - Token usage statistics
        - conversation_id: str - Unique identifier for the conversation
    """
    config = ConfigManager()

    LLAMA_API = config.get_llama_api()
    logger = get_logger()
    """Main function to get location advice with structured response handling"""

    # Format context and history
    formatted_candidates = format_top_candidates(top_candidates)

    # Handle history - now expecting pre-formatted string
    user_history = history if history else "No previous conversation"

    logger.debug("User history: %s", user_history.replace('\n', ' || '))
    logger.debug("Formatted candidates: %s", formatted_candidates)

    if flag == True:
        # Build API request
        api_request = build_location_request_search(
            prompt, formatted_candidates, user_history,
            latitude, longitude, search_radius
        )
    else:
        # Build API request
        api_request = build_location_request(
            prompt, formatted_candidates, user_history,
            latitude, longitude, search_radius
        )
    logger.debug(
        f"API request JSON from build_location_request: {api_request}")

    try:
        # Execute API call
        response = LLAMA_API.run(api_request)
        logger.info("Received response from LLAMA API.")
        logger.debug(f"Response: {response.json()}")

        # Process response
        extracted_json = extract_content(response.json())

    except Exception as e:
        logger.error("Location Advice API failed: %s", e)

    logger.debug("API response processed with result: %s", extracted_json)

    return extracted_json

# src/config_manager.py
import os
import json
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from llamaapi import LlamaAPI

from src.managers.state.state_manager import StateManager
from src.managers.state.json_state_manager import JSONStateManager
from src.managers.history.history_manager import HistoryManager
from src.managers.history.json_history_manager import JSONHistoryManager


class ConfigManager:
    """
    Manages application configuration and selects appropriate backend implementations.
    Replaces the old config.py file with a centralized configuration management system.
    """
    _instance = None
    _is_initialized = False

    def __new__(cls, config_file: str = "config.json"):
        """Implement singleton pattern for ConfigManager."""
        if cls._instance is None:
            cls._instance = super(ConfigManager, cls).__new__(cls)
        return cls._instance

    def __init__(self, config_file: str = "config.json"):
        """
        Initialize the ConfigManager.

        Args:
            config_file: Path to the configuration file
        """
        # Only initialize once (singleton pattern)
        if not self._is_initialized:
            self.config_file = config_file
            self.config = self._load_config()

            # Set the project root directory in the config if not already set
            if not self.config.get("project_root_dir"):
                self.config["project_root_dir"] = os.path.abspath(
                    os.path.dirname(__file__))
                self.update_config(
                    {"project_root_dir": self.config["project_root_dir"]})

            # Load environment variables
            load_dotenv()

            # Initialize API client
            api_key = self.get_api_key()
            self.llama_api = LlamaAPI(api_key) if api_key else None

            # Initialize common path variables
            self.root_dir = self.get_root_dir()
            self.tags_list_path = self.get_tags_list_path()
            self.category_subcategory_list_path = self.get_category_subcategory_path()
            self.dataset_path = self.get_dataset_path()

            # Mark as initialized
            self._is_initialized = True
            # self.logger = get_logger()

    def _load_config(self) -> Dict[str, Any]:
        """Load configuration from file or use defaults."""
        default_config = {
            "environment": "development",
            "state_backend": "json",
            "history_backend": "json",
            "sessions_dir": "sessions",
            "history_dir": "chat_history",
            "project_root_dir": os.path.abspath(os.path.dirname(__file__)),
            "data_paths": {
                "tags_list": "data/tags.csv",
                "category_subcategory_list": "data/category_subcategory.csv",
                "dataset": "data/dataset.csv"
            },
            "api_key_env_var": "apiKey"
        }

        # Try to load from file
        if os.path.exists(self.config_file):
            try:
                with open(self.config_file, 'r') as f:
                    return {**default_config, **json.load(f)}
            except Exception as e:
                print(f"Error loading config file: {str(e)}")
                return default_config
        else:
            # Create default config file
            try:
                with open(self.config_file, 'w') as f:
                    json.dump(default_config, f, indent=2)
            except Exception as e:
                print(f"Error creating default config file: {str(e)}")

            return default_config

    def get_state_manager(self) -> StateManager:
        """
        Get the appropriate StateManager implementation based on configuration.

        Returns:
            An instance of StateManager
        """
        backend = self.config.get("state_backend", "json")

        if backend == "json":
            return JSONStateManager(self.config.get("sessions_dir", "sessions"))
        elif backend == "redis":
            # For future implementation
            # self.logger.warning(
            #     "Redis state manager not implemented yet, falling back to JSON")
            return JSONStateManager(self.config.get("sessions_dir", "sessions"))
        else:
            # self.logger.warning(
            #     f"Unknown state backend: {backend}, using JSON")
            return JSONStateManager(self.config.get("sessions_dir", "sessions"))

    def get_history_manager(self) -> HistoryManager:
        """
        Get the appropriate HistoryManager implementation based on configuration.

        Returns:
            An instance of HistoryManager
        """
        backend = self.config.get("history_backend", "json")

        if backend == "json":
            return JSONHistoryManager(self.config.get("history_dir", "chat_history"))
        elif backend == "postgres":
            # For future implementation
            # self.logger.warning(
            #     "Postgres history manager not implemented yet, falling back to JSON")
            return JSONHistoryManager(self.config.get("history_dir", "chat_history"))
        else:
            # self.logger.warning(
            #     f"Unknown history backend: {backend}, using JSON")
            return JSONHistoryManager(self.config.get("history_dir", "chat_history"))

    def get_config_value(self, key: str, default: Any = None) -> Any:
        """
        Get a configuration value by key.

        Args:
            key: Configuration key
            default: Default value if key not found

        Returns:
            Configuration value
        """
        return self.config.get(key, default)

    def update_config(self, updates: Dict[str, Any]) -> bool:
        """
        Update configuration values.

        Args:
            updates: Dictionary of configuration updates

        Returns:
            True if successful, False otherwise
        """
        self.config.update(updates)

        try:
            with open(self.config_file, 'w') as f:
                json.dump(self.config, f, indent=2)
            return True
        except Exception as e:
            # self.logger.error(f"Error updating config file: {str(e)}")
            return False

    # Path management methods
    def get_root_dir(self) -> str:
        """Get the project root directory path."""
        return self.config.get("project_root_dir")

    def get_data_path(self, path_key: str) -> str:
        """
        Get the full path to a data file based on its config key.
        
        Args:
            path_key: Key in the data_paths config section
            
        Returns:
            Full path to the data file
        """
        data_paths = self.config.get("data_paths", {})
        relative_path = data_paths.get(path_key)

        if not relative_path:
            raise ValueError(
                f"Path for '{path_key}' not found in configuration")

        return os.path.join(self.get_root_dir(), relative_path)

    def get_api_key(self) -> str:
        """Get the API key from environment variables."""
        env_var = self.config.get("api_key_env_var", "apiKey")
        return os.getenv(env_var)

    # Convenience methods for common paths
    def get_tags_list_path(self) -> str:
        """Get the path to the tags list CSV file."""
        return self.get_data_path("tags_list")

    def get_category_subcategory_path(self) -> str:
        """Get the path to the category subcategory CSV file."""
        return self.get_data_path("category_subcategory_list")

    def get_dataset_path(self) -> str:
        """Get the path to the dataset CSV file."""
        return self.get_data_path("dataset")

    def get_llama_api(self) -> LlamaAPI:
        """Get the initialized LlamaAPI instance."""
        return self.llama_api
